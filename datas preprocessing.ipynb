{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04739339",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ea755",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"\"\"Human language is filled with ambiguities that make it incredibly difficult to write software that accurately determines the intended meaning of text or voice data. Homonyms, homophones, sarcasm, idioms, metaphors, grammar and usage exceptions, variations in sentence structure—these just a few of the irregularities of human language that take humans years to learn, but that programmers must teach natural language-driven applications to recognize and understand accurately from the start, if those applications are going to be useful.\n",
    "\n",
    "Several NLP tasks break down human text and voice data in ways that help the computer make sense of what it's ingesting. Some of these tasks include the following:\n",
    "\n",
    "Speech recognition, also called speech-to-text, is the task of reliably converting voice data into text data. Speech recognition is required for any application that follows voice commands or answers spoken questions. What makes speech recognition especially challenging is the way people talk—quickly, slurring words together, with varying emphasis and intonation, in different accents, and often using incorrect grammar.\n",
    "Part of speech tagging, also called grammatical tagging, is the process of determining the part of speech of a particular word or piece of text based on its use and context. Part of speech identifies ‘make’ as a verb in ‘I can make a paper plane,’ and as a noun in ‘What make of car do you own?’\n",
    "Word sense disambiguation is the selection of the meaning of a word with multiple meanings  through a process of semantic analysis that determine the word that makes the most sense in the given context. For example, word sense disambiguation helps distinguish the meaning of the verb 'make' in ‘make the grade’ (achieve) vs. ‘make a bet’ (place).\n",
    "Named entity recognition, or NEM, identifies words or phrases as useful entities. NEM identifies ‘Kentucky’ as a location or ‘Fred’ as a man's name.\n",
    "Co-reference resolution is the task of identifying if and when two words refer to the same entity. The most common example is determining the person or object to which a certain pronoun refers (e.g., ‘she’ = ‘Mary’),  but it can also involve identifying a metaphor or an idiom in the text  (e.g., an instance in which 'bear' isn't an animal but a large hairy person).\n",
    "Sentiment analysis attempts to extract subjective qualities—attitudes, emotions, sarcasm, confusion, suspicion—from text.\n",
    "Natural language generation is sometimes described as the opposite of speech recognition or speech-to-text; it's the task of putting structured information into human language.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7f6038",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd2dbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9419d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202314e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##tokenization- convert paragraph into sentences and focos on words\n",
    "nltk.download('punkt') #download this package first\n",
    "sentences=nltk.sent_tokenize(paragraph)   #convert para into sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b1ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cffb244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#porterstemmer used for stemming pupose\n",
    "#stemmer helps to find out the absolute  root word\n",
    "stemmer=PorterStemmer()\n",
    "stemmer.stem('natural')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa6cfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for lemmatization import library\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aac3321",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatizer helps to find good words/base words but with proper spelling\n",
    "lemmatizer.lemmatize('natural')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd88596",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the entire set\n",
    "import re\n",
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    #replace all special charectors\n",
    "    review=re.sub('[^a-zA-Z]',' ',sentences[i]) # return string obtain by replacing leftmost charector\n",
    "    review.lower() # convert into lower\n",
    "    corpus.append(review)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806dab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7facae",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a4f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply stemming\n",
    "for i in corpus:\n",
    "    words=nltk.word_tokenize(i)\n",
    "    for word in words:\n",
    "        if word not in set(stopwords.words('english')):\n",
    "            print(stemmer.stem(word))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc12161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply lemmatization\n",
    "for i in corpus:\n",
    "    words=nltk.word_tokenize(i)\n",
    "    for word in words:\n",
    "        if word not in set(stopwords.words('english')):\n",
    "            print(lemmatizer.lemmatize(word))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5045a3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply stopwords. lemmatize\n",
    "import re\n",
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    \n",
    "    review=re.sub('[^a-zA-Z]',' ',sentences[i]) \n",
    "    review=review.lower()\n",
    "    review=review.split()\n",
    "    review=[lemmatizer.lemmatize(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review=' '.join(review)\n",
    "    corpus.append(review)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f60b9d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bag of Words\n",
    "from sklearn.feature_extraction.text import  CountVectorizer\n",
    "cv=CountVectorizer(binary=False,ngram_range=(3,3)) #only trigrams\n",
    "x=cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9bbdc97d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'human language filled': 64,\n",
       " 'language filled ambiguity': 85,\n",
       " 'filled ambiguity make': 52,\n",
       " 'ambiguity make incredibly': 7,\n",
       " 'make incredibly difficult': 94,\n",
       " 'incredibly difficult write': 76,\n",
       " 'difficult write software': 39,\n",
       " 'write software accurately': 209,\n",
       " 'software accurately determines': 159,\n",
       " 'accurately determines intended': 1,\n",
       " 'determines intended meaning': 35,\n",
       " 'intended meaning text': 79,\n",
       " 'meaning text voice': 103,\n",
       " 'text voice data': 187,\n",
       " 'homonym homophone sarcasm': 62,\n",
       " 'homophone sarcasm idiom': 63,\n",
       " 'sarcasm idiom metaphor': 149,\n",
       " 'idiom metaphor grammar': 73,\n",
       " 'metaphor grammar usage': 106,\n",
       " 'grammar usage exception': 58,\n",
       " 'usage exception variation': 191,\n",
       " 'exception variation sentence': 50,\n",
       " 'variation sentence structure': 193,\n",
       " 'sentence structure irregularity': 155,\n",
       " 'structure irregularity human': 170,\n",
       " 'irregularity human language': 82,\n",
       " 'human language take': 65,\n",
       " 'language take human': 87,\n",
       " 'take human year': 175,\n",
       " 'human year learn': 67,\n",
       " 'year learn programmer': 210,\n",
       " 'learn programmer must': 89,\n",
       " 'programmer must teach': 132,\n",
       " 'must teach natural': 109,\n",
       " 'teach natural language': 182,\n",
       " 'natural language driven': 111,\n",
       " 'language driven application': 84,\n",
       " 'driven application recognize': 43,\n",
       " 'application recognize understand': 14,\n",
       " 'recognize understand accurately': 142,\n",
       " 'understand accurately start': 190,\n",
       " 'accurately start application': 2,\n",
       " 'start application going': 169,\n",
       " 'application going useful': 13,\n",
       " 'several nlp task': 157,\n",
       " 'nlp task break': 115,\n",
       " 'task break human': 177,\n",
       " 'break human text': 19,\n",
       " 'human text voice': 66,\n",
       " 'voice data way': 199,\n",
       " 'data way help': 32,\n",
       " 'way help computer': 200,\n",
       " 'help computer make': 60,\n",
       " 'computer make sense': 28,\n",
       " 'make sense ingesting': 98,\n",
       " 'task include following': 179,\n",
       " 'include following speech': 75,\n",
       " 'following speech recognition': 53,\n",
       " 'speech recognition also': 163,\n",
       " 'recognition also called': 137,\n",
       " 'also called speech': 5,\n",
       " 'called speech text': 21,\n",
       " 'speech text task': 168,\n",
       " 'text task reliably': 186,\n",
       " 'task reliably converting': 181,\n",
       " 'reliably converting voice': 145,\n",
       " 'converting voice data': 30,\n",
       " 'voice data text': 198,\n",
       " 'data text data': 31,\n",
       " 'speech recognition required': 165,\n",
       " 'recognition required application': 140,\n",
       " 'required application follows': 146,\n",
       " 'application follows voice': 12,\n",
       " 'follows voice command': 54,\n",
       " 'voice command answer': 197,\n",
       " 'command answer spoken': 26,\n",
       " 'answer spoken question': 11,\n",
       " 'make speech recognition': 99,\n",
       " 'speech recognition especially': 164,\n",
       " 'recognition especially challenging': 138,\n",
       " 'especially challenging way': 47,\n",
       " 'challenging way people': 24,\n",
       " 'way people talk': 201,\n",
       " 'people talk quickly': 125,\n",
       " 'talk quickly slurring': 176,\n",
       " 'quickly slurring word': 136,\n",
       " 'slurring word together': 158,\n",
       " 'word together varying': 208,\n",
       " 'together varying emphasis': 188,\n",
       " 'varying emphasis intonation': 194,\n",
       " 'emphasis intonation different': 45,\n",
       " 'intonation different accent': 80,\n",
       " 'different accent often': 38,\n",
       " 'accent often using': 0,\n",
       " 'often using incorrect': 118,\n",
       " 'using incorrect grammar': 192,\n",
       " 'part speech tagging': 123,\n",
       " 'speech tagging also': 167,\n",
       " 'tagging also called': 173,\n",
       " 'also called grammatical': 4,\n",
       " 'called grammatical tagging': 20,\n",
       " 'grammatical tagging process': 59,\n",
       " 'tagging process determining': 174,\n",
       " 'process determining part': 130,\n",
       " 'determining part speech': 36,\n",
       " 'part speech particular': 122,\n",
       " 'speech particular word': 162,\n",
       " 'particular word piece': 124,\n",
       " 'word piece text': 205,\n",
       " 'piece text based': 128,\n",
       " 'text based use': 183,\n",
       " 'based use context': 17,\n",
       " 'part speech identifies': 121,\n",
       " 'speech identifies make': 161,\n",
       " 'identifies make verb': 69,\n",
       " 'make verb make': 100,\n",
       " 'verb make paper': 196,\n",
       " 'make paper plane': 96,\n",
       " 'paper plane noun': 120,\n",
       " 'plane noun make': 129,\n",
       " 'noun make car': 116,\n",
       " 'make car word': 92,\n",
       " 'car word sense': 22,\n",
       " 'word sense disambiguation': 207,\n",
       " 'sense disambiguation selection': 153,\n",
       " 'disambiguation selection meaning': 41,\n",
       " 'selection meaning word': 150,\n",
       " 'meaning word multiple': 105,\n",
       " 'word multiple meaning': 203,\n",
       " 'multiple meaning process': 108,\n",
       " 'meaning process semantic': 102,\n",
       " 'process semantic analysis': 131,\n",
       " 'semantic analysis determine': 151,\n",
       " 'analysis determine word': 9,\n",
       " 'determine word make': 34,\n",
       " 'word make sense': 202,\n",
       " 'make sense given': 97,\n",
       " 'sense given context': 154,\n",
       " 'example word sense': 49,\n",
       " 'sense disambiguation help': 152,\n",
       " 'disambiguation help distinguish': 40,\n",
       " 'help distinguish meaning': 61,\n",
       " 'distinguish meaning verb': 42,\n",
       " 'meaning verb make': 104,\n",
       " 'verb make make': 195,\n",
       " 'make make grade': 95,\n",
       " 'make grade achieve': 93,\n",
       " 'grade achieve make': 57,\n",
       " 'achieve make bet': 3,\n",
       " 'make bet place': 91,\n",
       " 'named entity recognition': 110,\n",
       " 'entity recognition nem': 46,\n",
       " 'recognition nem identifies': 139,\n",
       " 'nem identifies word': 114,\n",
       " 'identifies word phrase': 70,\n",
       " 'word phrase useful': 204,\n",
       " 'phrase useful entity': 127,\n",
       " 'nem identifies kentucky': 113,\n",
       " 'identifies kentucky location': 68,\n",
       " 'kentucky location fred': 83,\n",
       " 'location fred man': 90,\n",
       " 'fred man name': 55,\n",
       " 'co reference resolution': 25,\n",
       " 'reference resolution task': 143,\n",
       " 'resolution task identifying': 147,\n",
       " 'task identifying two': 178,\n",
       " 'identifying two word': 72,\n",
       " 'two word refer': 189,\n",
       " 'word refer entity': 206,\n",
       " 'common example determining': 27,\n",
       " 'example determining person': 48,\n",
       " 'determining person object': 37,\n",
       " 'person object certain': 126,\n",
       " 'object certain pronoun': 117,\n",
       " 'certain pronoun refers': 23,\n",
       " 'pronoun refers mary': 133,\n",
       " 'refers mary also': 144,\n",
       " 'mary also involve': 101,\n",
       " 'also involve identifying': 6,\n",
       " 'involve identifying metaphor': 81,\n",
       " 'identifying metaphor idiom': 71,\n",
       " 'metaphor idiom text': 107,\n",
       " 'idiom text instance': 74,\n",
       " 'text instance bear': 184,\n",
       " 'instance bear animal': 78,\n",
       " 'bear animal large': 18,\n",
       " 'animal large hairy': 10,\n",
       " 'large hairy person': 88,\n",
       " 'sentiment analysis attempt': 156,\n",
       " 'analysis attempt extract': 8,\n",
       " 'attempt extract subjective': 15,\n",
       " 'extract subjective quality': 51,\n",
       " 'subjective quality attitude': 172,\n",
       " 'quality attitude emotion': 135,\n",
       " 'attitude emotion sarcasm': 16,\n",
       " 'emotion sarcasm confusion': 44,\n",
       " 'sarcasm confusion suspicion': 148,\n",
       " 'confusion suspicion text': 29,\n",
       " 'natural language generation': 112,\n",
       " 'language generation sometimes': 86,\n",
       " 'generation sometimes described': 56,\n",
       " 'sometimes described opposite': 160,\n",
       " 'described opposite speech': 33,\n",
       " 'opposite speech recognition': 119,\n",
       " 'speech recognition speech': 166,\n",
       " 'recognition speech text': 141,\n",
       " 'text task putting': 185,\n",
       " 'task putting structured': 180,\n",
       " 'putting structured information': 134,\n",
       " 'structured information human': 171,\n",
       " 'information human language': 77}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#featuture number\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9fca6b51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'human language filled ambiguity make incredibly difficult write software accurately determines intended meaning text voice data'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "dba83351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "06a4e535",
   "metadata": {},
   "outputs": [],
   "source": [
    "##tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "cv=TfidfVectorizer(ngram_range=(2,2),max_features=3)\n",
    "x=cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "411f27e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'human language filled ambiguity make incredibly difficult write software accurately determines intended meaning text voice data'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "769e60dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.]])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f328594",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
